---
title: "Socialness Ratings: Descriptives"
author: "Veronica Diveica"
output:
  word_document: default
This code provides summary statistics to characterize:
- the participant sample
- the item-wise socialness ratings
- the reliability and validity of the socialness measure

# Session Information:
# R version 3.6.1 (2019-07-05)
# Platform: x86_64-apple-darwin15.6.0 (64-bit)
# Running under: macOS Mojave 10.14.6, RStudio 1.2.5001
# 
# Locale: en_GB.UTF-8 / en_GB.UTF-8 / en_GB.UTF-8 / C / en_GB.UTF-8 / en_GB.UTF-8
# 
# Package version:
#   abind_1.4-5        askpass_1.1        assertthat_0.2.1   backports_1.2.1    base64enc_0.1-3    BH_1.69.0.1        blob_1.2.1        
#   bookdown_0.22      broom_0.7.9.9000   callr_3.5.1        cellranger_1.1.0   checkmate_2.0.0    cli_3.0.1          clipr_0.7.0       
#   codetools_0.2-16   colorspace_2.0-1   compiler_3.6.1     cowplot_1.0.0      cpp11_0.3.1        crayon_1.4.1       curl_4.3          
#   DBI_1.1.0          dbplyr_1.4.4       digest_0.6.27      dplyr_1.0.7        ellipsis_0.3.2     evaluate_0.14      fansi_0.5.0       
#   farver_2.1.0       forcats_0.5.1      foreach_1.5.1      fs_1.4.1           generics_0.1.0     ggplot2_3.3.3      glue_1.4.2        
#   graphics_3.6.1     grDevices_3.6.1    grid_3.6.1         gridExtra_2.3      gtable_0.3.0       haven_2.3.1        highr_0.9         
#   hms_0.5.3          htmltools_0.5.1.1  httr_1.4.1         isoband_0.2.4      iterators_1.0.13   jsonlite_1.7.2     knitr_1.33        
#   labeling_0.4.2     lattice_0.20-38    lifecycle_1.0.0    lubridate_1.7.9    magick_2.6.0       magrittr_2.0.1     markdown_1.1      
#   MASS_7.3-51.4      Matrix_1.2.17      matrixStats_0.56.0 methods_3.6.1      mgcv_1.8.28        mime_0.11          mnormt_1.5-5      
#   modelr_0.1.8       multicon_1.6       multilevel_2.6     munsell_0.5.0      mvtnorm_1.1-1      naniar_0.6.0       nlme_3.1-140      
#   openssl_1.4.1      pander_0.6.3       papaja_0.1.0.9997  parallel_3.6.1     pillar_1.6.2       pkgconfig_2.0.3    plyr_1.8.4        
#   prettyunits_1.1.1  processx_3.4.5     progress_1.2.2     pryr_0.1.4         ps_1.5.0           psych_2.1.6        psychometric_2.2  
#   purrr_0.3.4        R6_2.5.0           rapportools_1.0    RColorBrewer_1.1.2 Rcpp_1.0.6         readr_1.3.1        readxl_1.3.1      
#   rematch_1.0.1      reprex_0.3.0       reshape_0.8.8      rlang_0.4.11       rmarkdown_2.10     rmdfiltr_0.1.3     rstudioapi_0.13   
#   rvest_0.3.5        scales_1.1.1       sciplot_1.2-0      selectr_0.4.2      splines_3.6.1      stats_3.6.1        stringi_1.7.3     
#   stringr_1.4.0      summarytools_0.9.8 sys_3.3            tcltk_3.6.1        tibble_3.1.3       tidyr_1.1.3        tidyselect_1.1.1  
#   tidyverse_1.3.0    tinytex_0.33       tools_3.6.1        UpSetR_1.4.0       utf8_1.2.2         utils_3.6.1        vctrs_0.3.8       
#   viridis_0.5.1      viridisLite_0.4.0  visdat_0.5.3       whisker_0.4        withr_2.4.2        xfun_0.25          xml2_1.3.2        
#   yaml_2.2.1         zip_2.2.0  
---

```{r load packages, include=FALSE}
library(tidyverse)
library(summarytools)
library(naniar)
library(papaja)
library(multicon)  # for split-half reliability
library(psychometric) # for ICC2.lme
library(cowplot) # for plot_grid
```


```{r input data, include=FALSE}

# main experiment all data (including demographics and metadata)
raw_data <- read_csv("Data/Raw/All_data.csv")

# main experiment all clean data (including demographics and metadata)
data <- read_csv("Data/Preprocessed/Data_clean_all_words.csv") 

# main experiment clean ratings only
ratings <- read_csv("Data/Preprocessed/Ratings_FINAL.csv") 
  ratings <- ratings %>%
    column_to_rownames("ResponseId") %>%
    replace_with_na_all(condition = ~.x == 8)

# mean socialness ratings of control words from pilot study
control <- read_csv("Data/Raw/Control_words_pilot_ratings.csv")
control_words <- control$Word # extract list of control words

# item-wise summary statistics from pilot ratings
pilot_data <- read_csv("Pilot/Data/PILOT_Socialness_mean_ratings.csv") 
pilot_data <- pilot_data %>% dplyr::select("Word", "Mean")
colnames(pilot_data)[2] <- "Pilot_mean" 

# dominant part of speech
pos <- read_csv("Data/Other/SUBTLEX-US frequency list with PoS and Zipf information.csv")
  pos <- pos %>% dplyr::select(Word, Dom_PoS_SUBTLEX)

# Previous social interaction ratings
social.troche <- read_csv("Data/Other/Troche_2014_Social.csv")
  social.troche <- social.troche %>% dplyr::select(Word, Social) 
  colnames(social.troche)[2] <- "Social.Troche"
social.binder <- read_csv("Data/Other/Binder_SocialEmotion.csv")
  social.binder <- social.binder %>% dplyr::select(Word, Social) 
  colnames(social.binder)[2] <- "Social.Binder"

```

**Participant Sample**

Participants were recruited via the online platform Prolific (https://www.prolific.co/). Responders were restricted to those who self-reported being fluent in English and having no language disorders. A total of N = `r nrow(raw_data)` participants (`r sum(raw_data$D_Q2 == 'Male')` male, `r sum(raw_data$D_Q2 == 'Female')` female, `r sum(raw_data$D_Q2 == 'Other')` unspecified, *Mage* = `r round(mean(raw_data$D_Q1), digits = 2)` , *SDage* = `r round(sd(raw_data$D_Q1), digits = 2)`) completed the study. Participants completed the rating task in `r round(mean(raw_data$"Duration (in seconds)")/60)` minutes on average and were compensated with GBP Â£4. Following exclusions (see below), the final sample consisted of `r nrow(data)` participants, with ages ranging from `r min(data$D_Q1)` to `r max(data$D_Q1)` years (*M* = `r round(mean(data$D_Q1), digits = 2)`; *SD* = `r round(sd(data$D_Q1), digits = 2)`). Of the participants, `r sum(data$D_Q2 == 'Female')` (`r round(sum(data$D_Q2 == 'Female')*100/nrow(data), digits = 2)`%) were female, `r sum(data$D_Q2 == 'Male')` (`r round(sum(data$D_Q2 == 'Male')*100/nrow(data), digits = 2)`%) male and `r sum(data$D_Q2 == 'Other')` (`r round(sum(data$D_Q2 == 'Other')*100/nrow(data), digits = 2)`%) unspecified. English was the first language for `r sum(data$D_Q3 == 'Yes')` (`r round(sum(data$D_Q3 == 'Yes')*100/nrow(data), digits = 2)`%) participants. Of the remaining `r sum(data$D_Q3 == 'No')` (`r round(sum(data$D_Q3 == 'No')*100/nrow(data), digits = 2)`%) participants, `r sum(data$D_Q4 == 'Proficient', na.rm = TRUE)` self-reported as being proficient in English, `r sum(data$D_Q4 == 'Advanced', na.rm = TRUE)` advanced and `r sum(data$D_Q4 == 'Intermediate' | data$D_Q4 == 'Beginner', na.rm = TRUE)` beginner/intermediate. A total of `r sum(data$D_Q5 == 'No')` (`r round(sum(data$D_Q5 == 'No')*100/nrow(data), digits = 2)`%) participants were monolingual, while the remaining `r sum(data$D_Q5 == 'Yes (please specify)')` (`r round(sum(data$D_Q5 == 'Yes (please specify)')*100/nrow(data), digits = 2)`%) reported speaking more than one language.   


```{r ratings descriptives, include = FALSE}

# compute descriptive stats for each word
ratings_output <- pivot_longer(ratings,everything(), names_to = "Word", values_to = "Rating") %>% group_by(Word) %>% summarise(mean = mean(Rating, na.rm = TRUE), sd = sd(Rating, na.rm = TRUE), median = median(Rating, na.rm = TRUE), min = min(Rating, na.rm = TRUE), max = max(Rating, na.rm = TRUE), N = length(Rating[!is.na(Rating)]))
  colnames(ratings_output) <- c("Word", "Mean", "SD", "Median", "Min", "Max", "N")
# write_csv(ratings_output, "Data/Ratings_sum.stat.csv")
  
# compute descriptives for the mean socialness ratings
descr_social <- round(descr(ratings_output[,2], order = "preserve", transpose = TRUE), digits = 2)
  # prepare descriptives dataframe for apa formatted table
  descr_social <- descr_social %>% dplyr::select(Mean, Median, Std.Dev, Min, Max, Q1, Q3, Skewness, Kurtosis) 
  colnames(descr_social) <- c("Mean", "Median", "Standard Deviation", "Minimum", "Maximum", "1st Quartile", "3rd Quartile", "Skewness", "Kurtosis")
  descr_social <- descr_social %>% t() %>% as.data.frame() %>% rownames_to_column() 
  colnames(descr_social) <- c("Descriptive Statistic", "Value")
  
# prepare data for examples table
max_social <- ratings_output %>% slice_max(order_by = Mean, n = 25, with_ties = FALSE) %>% dplyr::select(Word, Mean)
min_social <- slice_min(ratings_output, order_by = Mean, n = 25, with_ties = FALSE) %>% dplyr::select(Word, Mean)
example_words <- cbind(max_social, min_social)
colnames(example_words) <- c("Highest-rated Words", "Rating", "Lowest-Rated Words", "Rating") 

# visualize distribution of mean socialness ratings
p1 <- ggplot(ratings_output, aes(Mean)) +
  geom_histogram(bins = 30, colour="black", fill= "limegreen", alpha=.3)+ 
  geom_vline(aes(xintercept = mean(Mean)),linetype = "dashed", size = 0.6) +
  theme_apa() + theme(axis.title = element_text(size = 22), axis.text = element_text(size = 20)) + labs(x = "Socialness Rating", y ="Count") + coord_cartesian(xlim = c(1,7), ylim = c(0, 550), expand = FALSE)

# visualize distribution of mean socialness ratings by Part of Speech
 # prepare data
  ratings_output_pos <- left_join(ratings_output, pos, by = "Word")
  ratings_output_pos <- ratings_output_pos %>% subset(Dom_PoS_SUBTLEX == "Verb" | Dom_PoS_SUBTLEX == "Noun" | Dom_PoS_SUBTLEX == "Adjective")
# create plot
p2 <- ggplot(ratings_output_pos, aes(Mean, fill = Dom_PoS_SUBTLEX, colour = Dom_PoS_SUBTLEX)) + 
  geom_density(alpha=.4) + 
  theme_apa() + theme(axis.title = element_text(size = 20), axis.text = element_text(size = 18), legend.text = element_text(size = 17), legend.title = element_text(size = 17), legend.position = c("0.9", "0.8"))+ guides(color = FALSE) + labs(x = "Socialness Rating", y ="Density", fill = "Part of Speech") + coord_cartesian(xlim = c(1,7), ylim = c(0, 0.4), expand = FALSE) 

# visualize relationship between SD and mean of socialness ratings
p3 <- ggplot(ratings_output, aes(x=Mean, y=SD)) +
  geom_point(shape=1, alpha = .3) +
  geom_smooth(colour = "limegreen") +
  theme_apa() + theme(axis.title = element_text(size = 20), axis.text = element_text(size = 18)) + labs(x = "Mean Rating", y ="SD") + coord_cartesian(xlim = c(1,7), ylim = c(0, 3), expand = FALSE)

```

**Descriptive Statistics**

The resulting socialness ratings are provided on the OSF project page. The socialness ratings have a unimodal distribution with a mean of `r round(mean(ratings_output$Mean), digits = 2)` (*SD* = `r round(sd(ratings_output$Mean), digits = 2)`) (Figure 1A). More descriptive statistics for the mean ratings are provided in Table 1. The ratings have an average standard deviation of `r round(mean(ratings_output$SD), digits = 2)` (*SD* = `r round(sd(ratings_output$SD), digits = 2)`) and participants provided more consistent responses at the extremes of the scale (Figure 1C). Examples of words at the extremes of the socialness dimension are given in Table 2. Words like *friendship*, *people* and *sociable* received high socialness values, while words like *avalanche*, *millimeter* and *hemoglobin* received low socialness ratings, suggesting good face validity. 

```{r descriptives table , echo=FALSE, message=FALSE}

#Create table of descriptive statistics fig.height = 8, fig.width = 20
apa_table(descr_social, caption = "Descriptive Statistics for Socialness Ratings for 8,388 Words.", row.names = FALSE)

```

```{r examples table and distribution figure, echo=FALSE, message=FALSE, fig.width=20, fig.height=8}

#Create table of example words
apa_table(example_words, caption = "List of words at the extremes of the socialness dimension.", row.names = FALSE, digits = 2)

# Figure1. Distribution of Socialness Ratings & Relationship to SD
fig1_right <- plot_grid(p2, p3, labels = c("B.", "C."), nrow = 2,  ncol = 1, label_size = 25, align = "hv")
fig1 <- plot_grid(p1, fig1_right, labels = c("A.", " "), label_size = 25, ncol = 2, nrow = 1, rel_widths = c(1.5, 1))+ theme(plot.margin = margin(20, 20, 20, 20, "pt"))
# visualize
fig1
# save
ggsave("Figures/Distribution.tiff", width = 20, height = 8)
ggsave("Figures/Distribution.png", width = 20, height = 8)


```

```{r reliability and validity, echo = FALSE}

# Split-half reliability
# prepare data
control_ratings <- ratings %>% dplyr::select(all_of(control_words)) %>% as.data.frame()  
reliability_data <- as.data.frame(t(control_ratings)) # participants on columns
# run split-half test
splithalf_rel <- splithalf.r(reliability_data, sims = 100, seed = 2, graph = FALSE)

# One-way intra-class correlation coefficient ICC(k)
data_icc <- pivot_longer(ratings,everything(), names_to = "word", values_to = "rating") # prepare data
icc.k <- ICC2.lme(rating, word, data = data_icc, weighted = TRUE) # restimate one-way ICC via a random effects model 

# Validity
# prepare data 
val_data<- left_join(ratings_output, pilot_data, by = "Word")
val_data<- left_join(val_data, social.binder, by = "Word")
val_data<- left_join(val_data, social.troche, by = "Word")
val_data <- val_data %>% dplyr::select(Word, Mean, Pilot_mean, Social.Troche, Social.Binder) 
# compute correlation with pilot mean ratings 
corr_pilot <- cor(val_data$Mean, val_data$Pilot_mean, use = "complete.obs")
# compute correlation with previous social interaction ratings
corr_Binder <- cor(val_data$Mean, val_data$Social.Binder, use = "complete.obs")
corr_Troche <- cor(val_data$Mean, val_data$Social.Troche, use = "complete.obs")

```
**Reliability and Validity**

We first examined the reliability of the ratings by computing the one-way intra-class correlation coefficient (ICC) of all ratings using variances estimated via a random effects model with a global intercept and a random intercept per word (Brysbaert, 2019; Stevens & Brysbaert, 2016). We found an ICC of `r round(icc.k, digits = 2)` which indicates good reliability of the mean socialness ratings. We further computed the split-half reliability for the 30 control words which were the only items in our dataset rated by all participants. We found a mean Spearman-Brown corrected split-half reliability of `r round(splithalf_rel[3], digits = 3)` (*SD* = `r round(splithalf_rel[4], digits = 2)`) across 100 random splits, suggesting high reliability for the control items.

We then examined the validity of the ratings by computing the correlations between the ratings observed here and the mean ratings collected in the pilot study (*n* = `r length(which(!is.na(val_data$Pilot_mean)))` words), as well as two previous related sets of social interaction norms collected by Binder et al. (2016) (*n* = `r length(which(!is.na(val_data$Social.Binder)))` words), and Troche et al. (2017) (*n* = `r length(which(!is.na(val_data$Social.Troche)))` words). The current socialness ratings were strongly and positively correlated with the ratings collected in the pilot study (*r* = `r round(corr_pilot, digits = 2)`) with the previous social interaction ratings collected by Binder et al. (2016) (*r* = `r round(corr_Binder, digits = 2)`) and Troche et al. (2017) (*r* = `r round(corr_Binder, digits = 2)`), suggesting good validity.  

